DSP rebalance started at 2025-04-05 09:58:41
```
2025-04-05 10:03:38,751 1881 root INFO dsp_pod test_attribute_cache_interactions_with_osd Activated dsp pods counts per node : {'c0n0': 0, 'c0n1': 6, 'c0n2': 6}
2025-04-05 10:03:38,763 1881 root INFO dsp_pod test_attribute_cache_interactions_with_osd Pod distribution across nodes: {'c0n0': 0, 'c0n1': 6, 'c0n2': 6}
2025-04-05 10:03:38,763 1881 root WARNING dsp_pod test_attribute_cache_interactions_with_osd Node c0n0 has an unexpected DSP pod count: 0
```
Script is checking the pod rebalance at 2025-04-05 10:28:45 still rebalance is not happening and Test case is failed.

What's the issue with c0n0 around the 10:00 mark?

dspmapper logs shows handling data not ready on c0n0 at 9:56:19 
```
2025-04-05T09:56:19.196711405Z stdout F [INFO] 2025-04-05,09:56:19.193838Z dspmapper.go:75] Current state: HandlingDataNotReady
2025-04-05T09:56:19.196713959Z stdout F [DEBUG] 2025-04-05,09:56:19.193852Z statemachine.go:277] Calling onStep() of state HandlingDataNotReady
2025-04-05T09:56:19.196716023Z stdout F [INFO] 2025-04-05,09:56:19.194583Z k8sclient.go:256] Adding node label key:node-data-not-ready value: to node:c0n0
2025-04-05T09:56:19.211119948Z stdout F [DEBUG] 2025-04-05,09:56:19.207623Z k8sclient.go:506] Gathering pods running on node c0n0 and matching label type=data in ds-dsp namespace
2025-04-05T09:56:19.233675713Z stdout F [DEBUG] 2025-04-05,09:56:19.23278Z k8sclient.go:535] Found 4 pods in namespace ds-dsp matching label type=data and running on node c0n0
2025-04-05T09:56:19.233686924Z stdout F [INFO] 2025-04-05,09:56:19.232853Z k8sclient.go:540] Deleting Pod dsp-30696-84fd6f44df-z5bzl in namespace:ds-dsp
2025-04-05T09:56:19.244253864Z stdout F [INFO] 2025-04-05,09:56:19.24324Z k8sclient.go:540] Deleting Pod dsp-52197-86c487c67f-cq5z8 in namespace:ds-dsp
2025-04-05T09:56:19.26214768Z stdout F [INFO] 2025-04-05,09:56:19.261849Z k8sclient.go:540] Deleting Pod dsp-57072-8fd49fdf8-whnzl in namespace:ds-dsp
2025-04-05T09:56:19.293584771Z stdout F [INFO] 2025-04-05,09:56:19.29306Z k8sclient.go:540] Deleting Pod dsp-60292-675666776f-jsr7p in namespace:ds-dsp
```
then the dsp mapper logs shows handling data ready at 9:58.59
```
2025-04-05T09:58:59.21430257Z stdout F [INFO] 2025-04-05,09:58:59.213956Z dspmapper.go:75] Current state: HandlingDataReady
2025-04-05T09:58:59.214304494Z stdout F [DEBUG] 2025-04-05,09:58:59.213984Z statemachine.go:277] Calling onStep() of state HandlingDataReady
2025-04-05T09:58:59.247037458Z stdout F [DEBUG] 2025-04-05,09:58:59.244562Z handlingdatareadystate.go:25] Processed data ready state for node c0n0
```
dspmapper stops logging at 9:58:59

npd:
START= 2025-04-05T07:40:28     END= 2025-04-05T09:58:48     ./dna_decompress/hfsim-rd-cluster/log.250405.103604.0001/c0n0/var/log/pods/ds_npd-0aacb7e6-44vsc_a39f4f06-8d4e-43b3-8c43-1316ee3a4725/node-problem-detector/0.log
```
2025-04-05T09:58:48.18327357Z stderr F I0405 09:58:48.183144       1 custom_plugin_monitor.go:280] New status generated: &{Source:data-ready-check Events:[{Severity:info Timestamp:2025-04-05 09:58:48.183083197 +0000 UTC m=+8300.078879181 Reason:NodeDataReady Message:Node condition DataNotReady is now: False, reason: NodeDataReady, message: "Node is data ready"}] Conditions:[{Type:DataNotReady Status:False Transition:2025-04-05 09:58:48.183083197 +0000 UTC m=+8300.078879181 Reason:NodeDataReady Message:Node is data ready}]}
```

no descheduler is running past 9:27:47
START= 2025-04-05T09:27:09     END= 2025-04-05T09:27:47     ./post-test-session/artifacts_20250405_102951_436349/dna_decompress/hfsim-rd-cluster/log.250405.103604.0001/c0n0/var/log/pods_archive/ds_descheduler-5dc64d76c6-4mssk_a668ccaf-d030-4bda-b961-8b456cce7dde/descheduler/0.log

kubescheduler deletes the descheduler and it never gets rescheduled
```
2025-04-05T09:27:48.677139939Z stderr F I0405 09:27:48.676341       1 eventhandlers.go:244] "Delete event for scheduled pod" pod="ds/descheduler-5dc64d76c6-4mssk"
```

Doesn't appear like the deployment was deleted by looking at the kube-apiserver logs at that time
 
Double check user agent to look for kubernetes

userAgents are openAPI generator python so i think that the test 

kube controller manager

./fleetos/object/minio/error_recovery_tests/test_dsp_cases.py
test func: Â test_attribute_cache_interactions_with_osd()

test_restart_dsp_and_provd()
disabled descheduler at 9:27:47

pytest_stdout show error

